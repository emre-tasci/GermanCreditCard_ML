{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_HW1_YunusEmreTasci_25467.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTfDIhAYYjaX",
        "colab_type": "text"
      },
      "source": [
        "# Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGi6c-0uZSeB",
        "colab_type": "code",
        "outputId": "504fac4f-d304-4e1d-a38b-d50301ddf6c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFpeyxi8aqIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You can find the data under https://drive.google.com/drive/folders/1e550az93U3_kfRBbVY5PZnMKYwGYmHqi?usp=sharing\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train_data =pd.read_csv( \"/content/drive/My Drive/HW1/train_data.csv\")\n",
        "train_label =pd.read_csv( \"/content/drive/My Drive/HW1/train_label.csv\")\n",
        "test_data = pd.read_csv( \"/content/drive/My Drive/HW1/test_data.csv\")\n",
        "test_label = pd.read_csv( \"/content/drive/My Drive/HW1/test_label.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZXqzZlXBIN0",
        "colab_type": "code",
        "outputId": "9cb25422-0cba-4a83-bd21-543dc1dc13ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "# show random samples from the training data\n",
        "train_data.head()\n",
        "\n",
        "# One line of code"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>duration</th>\n",
              "      <th>credit_amount</th>\n",
              "      <th>installment_commitment</th>\n",
              "      <th>residence_since</th>\n",
              "      <th>age</th>\n",
              "      <th>existing_credits</th>\n",
              "      <th>num_dependents</th>\n",
              "      <th>f_worker</th>\n",
              "      <th>checking_status_&lt;0</th>\n",
              "      <th>checking_status_&gt;=200</th>\n",
              "      <th>checking_status_no checking</th>\n",
              "      <th>credit_history_critical/other existing credit</th>\n",
              "      <th>credit_history_delayed previously</th>\n",
              "      <th>credit_history_existing paid</th>\n",
              "      <th>credit_history_no credits/all paid</th>\n",
              "      <th>purpose_domestic appliance</th>\n",
              "      <th>purpose_education</th>\n",
              "      <th>purpose_furniture/equipment</th>\n",
              "      <th>purpose_new car</th>\n",
              "      <th>purpose_other</th>\n",
              "      <th>purpose_radio/tv</th>\n",
              "      <th>purpose_repairs</th>\n",
              "      <th>purpose_retraining</th>\n",
              "      <th>purpose_used car</th>\n",
              "      <th>savings_status_500&lt;=X&lt;1000</th>\n",
              "      <th>savings_status_&lt;100</th>\n",
              "      <th>savings_status_&gt;=1000</th>\n",
              "      <th>savings_status_no known savings</th>\n",
              "      <th>employment_4&lt;=X&lt;7</th>\n",
              "      <th>employment_&lt;1</th>\n",
              "      <th>employment_&gt;=7</th>\n",
              "      <th>employment_unemployed</th>\n",
              "      <th>personal_status_male div/sep</th>\n",
              "      <th>personal_status_male mar/wid</th>\n",
              "      <th>personal_status_male single</th>\n",
              "      <th>other_parties_guarantor</th>\n",
              "      <th>other_parties_none</th>\n",
              "      <th>property_magnitude_life insurance</th>\n",
              "      <th>property_magnitude_no known property</th>\n",
              "      <th>property_magnitude_real estate</th>\n",
              "      <th>other_payment_plans_none</th>\n",
              "      <th>other_payment_plans_stores</th>\n",
              "      <th>housing_own</th>\n",
              "      <th>housing_rent</th>\n",
              "      <th>job_skilled</th>\n",
              "      <th>job_unemp/unskilled non res</th>\n",
              "      <th>job_unskilled resident</th>\n",
              "      <th>own_telephone_yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1169</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>67</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>48</td>\n",
              "      <td>5951</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>2096</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>42</td>\n",
              "      <td>7882</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>24</td>\n",
              "      <td>4870</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>53</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  duration  ...  job_unskilled resident  own_telephone_yes\n",
              "0   1         6  ...                       0                  1\n",
              "1   2        48  ...                       0                  0\n",
              "2   3        12  ...                       1                  0\n",
              "3   4        42  ...                       0                  0\n",
              "4   5        24  ...                       0                  0\n",
              "\n",
              "[5 rows x 49 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfdOMtebODrA",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SqCrltyN8gl",
        "colab_type": "code",
        "outputId": "4f188e52-80ac-4220-956e-d801faa2850b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "train_label\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>789</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>790</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>791</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>792</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>793 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     label\n",
              "0        1\n",
              "1        0\n",
              "2        1\n",
              "3        1\n",
              "4        0\n",
              "..     ...\n",
              "788      0\n",
              "789      0\n",
              "790      0\n",
              "791      1\n",
              "792      1\n",
              "\n",
              "[793 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3qKhpTp5BJ4",
        "colab_type": "code",
        "outputId": "8c7be798-a097-4bd1-f4cf-2c2c48c60d37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "test_label"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>207 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     label\n",
              "0        1\n",
              "1        1\n",
              "2        1\n",
              "3        0\n",
              "4        1\n",
              "..     ...\n",
              "202      1\n",
              "203      1\n",
              "204      1\n",
              "205      0\n",
              "206      1\n",
              "\n",
              "[207 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQIVU4-zXpE_",
        "colab_type": "text"
      },
      "source": [
        "# Train Decision Tree with default parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLznLl_lXYZf",
        "colab_type": "code",
        "outputId": "2a495bf0-de82-4fa7-ebf6-fb8fb47bfbf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "clf = DecisionTreeClassifier(criterion='entropy',)\n",
        "clf = clf.fit(train_data, train_label)\n",
        "\n",
        "# Estimate the prediction of test data\n",
        "test_pred = clf.predict(test_data)\n",
        "\n",
        "# Calculate accuracy of test data\n",
        "from sklearn.metrics import accuracy_score\n",
        "TestAcc =accuracy_score(test_label, test_pred)\n",
        "print(\"Testing Accuracy = %.5f%%\" % (TestAcc * 100))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Accuracy = 67.63285%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqgNZYUMXv8X",
        "colab_type": "text"
      },
      "source": [
        "# FineTune Decision Tree parameters\n",
        "\n",
        "1- Spliting dataset into train and validation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWJxk-zjy0Kv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Split training data to 70% training and 30% validation\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(train_data,train_label,test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqws-kTZYHoG",
        "colab_type": "text"
      },
      "source": [
        "2- FineTune minimum sample split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1DvpmCCJXTb",
        "colab_type": "code",
        "outputId": "d9acb713-a064-4246-a2d3-744c5415e8c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "min_samples_splits = range(2, 100)\n",
        "\n",
        "train_results = []\n",
        "val_results = []\n",
        "for mss in min_samples_splits:\n",
        "  \n",
        "  # Fit the tree using the 70% portion of the training data\n",
        "  dt=DecisionTreeClassifier(min_samples_split=mss ,criterion='entropy')\n",
        "  dt.fit(x_train, y_train)\n",
        "  # One line of code\n",
        "  # One line of code\n",
        "  \n",
        "  # Evaluate on Training set\n",
        "  train_pred =dt.predict(x_train) # One line of code\n",
        "  train_acc =accuracy_score(y_train,train_pred) # One line of code\n",
        "  train_results.append(train_acc)\n",
        "   \n",
        "  # Evaluate on Validation set\n",
        "  val_pred = dt.predict(x_val)# One line of code\n",
        "  val_acc = accuracy_score(y_val,val_pred)# One line of code\n",
        "  val_results.append(val_acc)\n",
        "  print(\"mss\",mss, \"// accuracy = \", val_acc)\n",
        "# Ploting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(min_samples_splits, train_results, 'b')\n",
        "plt.plot(min_samples_splits, val_results,'r')\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mss 2 // accuracy =  0.7016806722689075\n",
            "mss 3 // accuracy =  0.6680672268907563\n",
            "mss 4 // accuracy =  0.6848739495798319\n",
            "mss 5 // accuracy =  0.6722689075630253\n",
            "mss 6 // accuracy =  0.6680672268907563\n",
            "mss 7 // accuracy =  0.6764705882352942\n",
            "mss 8 // accuracy =  0.6722689075630253\n",
            "mss 9 // accuracy =  0.6764705882352942\n",
            "mss 10 // accuracy =  0.6680672268907563\n",
            "mss 11 // accuracy =  0.6764705882352942\n",
            "mss 12 // accuracy =  0.680672268907563\n",
            "mss 13 // accuracy =  0.6764705882352942\n",
            "mss 14 // accuracy =  0.6722689075630253\n",
            "mss 15 // accuracy =  0.6680672268907563\n",
            "mss 16 // accuracy =  0.6932773109243697\n",
            "mss 17 // accuracy =  0.7058823529411765\n",
            "mss 18 // accuracy =  0.6932773109243697\n",
            "mss 19 // accuracy =  0.7142857142857143\n",
            "mss 20 // accuracy =  0.7184873949579832\n",
            "mss 21 // accuracy =  0.7142857142857143\n",
            "mss 22 // accuracy =  0.7058823529411765\n",
            "mss 23 // accuracy =  0.7100840336134454\n",
            "mss 24 // accuracy =  0.7058823529411765\n",
            "mss 25 // accuracy =  0.7058823529411765\n",
            "mss 26 // accuracy =  0.6890756302521008\n",
            "mss 27 // accuracy =  0.6890756302521008\n",
            "mss 28 // accuracy =  0.7100840336134454\n",
            "mss 29 // accuracy =  0.7142857142857143\n",
            "mss 30 // accuracy =  0.7100840336134454\n",
            "mss 31 // accuracy =  0.7100840336134454\n",
            "mss 32 // accuracy =  0.7142857142857143\n",
            "mss 33 // accuracy =  0.7142857142857143\n",
            "mss 34 // accuracy =  0.7184873949579832\n",
            "mss 35 // accuracy =  0.7184873949579832\n",
            "mss 36 // accuracy =  0.7184873949579832\n",
            "mss 37 // accuracy =  0.7142857142857143\n",
            "mss 38 // accuracy =  0.7184873949579832\n",
            "mss 39 // accuracy =  0.7184873949579832\n",
            "mss 40 // accuracy =  0.7226890756302521\n",
            "mss 41 // accuracy =  0.7226890756302521\n",
            "mss 42 // accuracy =  0.7226890756302521\n",
            "mss 43 // accuracy =  0.7226890756302521\n",
            "mss 44 // accuracy =  0.7226890756302521\n",
            "mss 45 // accuracy =  0.7226890756302521\n",
            "mss 46 // accuracy =  0.7226890756302521\n",
            "mss 47 // accuracy =  0.7226890756302521\n",
            "mss 48 // accuracy =  0.7226890756302521\n",
            "mss 49 // accuracy =  0.7226890756302521\n",
            "mss 50 // accuracy =  0.7226890756302521\n",
            "mss 51 // accuracy =  0.7226890756302521\n",
            "mss 52 // accuracy =  0.7226890756302521\n",
            "mss 53 // accuracy =  0.726890756302521\n",
            "mss 54 // accuracy =  0.726890756302521\n",
            "mss 55 // accuracy =  0.726890756302521\n",
            "mss 56 // accuracy =  0.726890756302521\n",
            "mss 57 // accuracy =  0.726890756302521\n",
            "mss 58 // accuracy =  0.726890756302521\n",
            "mss 59 // accuracy =  0.726890756302521\n",
            "mss 60 // accuracy =  0.726890756302521\n",
            "mss 61 // accuracy =  0.7142857142857143\n",
            "mss 62 // accuracy =  0.7142857142857143\n",
            "mss 63 // accuracy =  0.7142857142857143\n",
            "mss 64 // accuracy =  0.7058823529411765\n",
            "mss 65 // accuracy =  0.7058823529411765\n",
            "mss 66 // accuracy =  0.7058823529411765\n",
            "mss 67 // accuracy =  0.7058823529411765\n",
            "mss 68 // accuracy =  0.7058823529411765\n",
            "mss 69 // accuracy =  0.7058823529411765\n",
            "mss 70 // accuracy =  0.7058823529411765\n",
            "mss 71 // accuracy =  0.7058823529411765\n",
            "mss 72 // accuracy =  0.7058823529411765\n",
            "mss 73 // accuracy =  0.7058823529411765\n",
            "mss 74 // accuracy =  0.7058823529411765\n",
            "mss 75 // accuracy =  0.7058823529411765\n",
            "mss 76 // accuracy =  0.7058823529411765\n",
            "mss 77 // accuracy =  0.7058823529411765\n",
            "mss 78 // accuracy =  0.7058823529411765\n",
            "mss 79 // accuracy =  0.7226890756302521\n",
            "mss 80 // accuracy =  0.7226890756302521\n",
            "mss 81 // accuracy =  0.7226890756302521\n",
            "mss 82 // accuracy =  0.7226890756302521\n",
            "mss 83 // accuracy =  0.7226890756302521\n",
            "mss 84 // accuracy =  0.7226890756302521\n",
            "mss 85 // accuracy =  0.7226890756302521\n",
            "mss 86 // accuracy =  0.7226890756302521\n",
            "mss 87 // accuracy =  0.7226890756302521\n",
            "mss 88 // accuracy =  0.7226890756302521\n",
            "mss 89 // accuracy =  0.7226890756302521\n",
            "mss 90 // accuracy =  0.7226890756302521\n",
            "mss 91 // accuracy =  0.7226890756302521\n",
            "mss 92 // accuracy =  0.7226890756302521\n",
            "mss 93 // accuracy =  0.7226890756302521\n",
            "mss 94 // accuracy =  0.7226890756302521\n",
            "mss 95 // accuracy =  0.7226890756302521\n",
            "mss 96 // accuracy =  0.7226890756302521\n",
            "mss 97 // accuracy =  0.7226890756302521\n",
            "mss 98 // accuracy =  0.7226890756302521\n",
            "mss 99 // accuracy =  0.7226890756302521\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wOzId8umBHFvAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PM_mwwzOKmwd",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akVAE3MbL7bE",
        "colab_type": "code",
        "outputId": "f86ad9cb-237b-423e-c863-80fc828b96a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Choose the best minimum split sample based on the plot\n",
        "Best_minSampl=np.argmax(val_results)\n",
        "\n",
        "print(\"Best_minSampl is\", np.argmax(val_results))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best_minSampl is 51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8MFGuiOIaHm",
        "colab_type": "code",
        "outputId": "ba146364-b968-444c-eaf5-9bca3aed240e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Train decision tree using the full training data and the best minimum split sample\n",
        "dt1 = DecisionTreeClassifier(criterion='entropy', min_samples_split=Best_minSampl)\n",
        "dt1 = dt1.fit(train_data, train_label)\n",
        "# Estimate the prediction of the test data\n",
        "test_pred =dt1.predict(test_data)\n",
        " # One line of code\n",
        "\n",
        "# Calculate accuracy of test data\n",
        "TestAccc = accuracy_score(test_label, test_pred)\n",
        "print(\"Testing Accuracy = %.5f%%\" % (TestAccc * 100))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Accuracy = 71.49758%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VciE0lfYKhya",
        "colab_type": "text"
      },
      "source": [
        "# Now, apply the same procedure but using KNN instead of decision tree \n",
        "\n",
        "# For finetuning, find the best value of K to use with this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA7o_GwjCiSn",
        "colab_type": "code",
        "outputId": "44269b0c-d8f1-4ea2-d03b-97702ee1220b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics\n",
        "knn =KNeighborsClassifier()\n",
        "knn = knn.fit(train_data, train_label)\n",
        "\n",
        "# Estimate the prediction of test data\n",
        "test_pred1 = knn.predict(test_data)\n",
        "\n",
        "# Calculate accuracy of test data\n",
        "from sklearn.metrics import accuracy_score\n",
        "TestAcc =accuracy_score(test_label, test_pred1)\n",
        "print(\"Testing Accuracy = %.5f%%\" % (TestAcc * 100))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Accuracy = 67.63285%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdBaXNKoLBcL",
        "colab_type": "code",
        "outputId": "37823f8c-dcc1-4397-a34e-8af1a1822742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        }
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics\n",
        "# initialize the values of k to be a list of odd numbers between 1 and 30\n",
        "kVals = list(range(1, 30, 2))\n",
        "\n",
        "train_results2 = []\n",
        "val_results_Knn = []\n",
        "# Save the accuracies of each value of kVal in [accuracies] variable\n",
        "# hint: you can use accuracies.append(...) function inside the loop\n",
        "accuracies = []\n",
        "\n",
        "# loop over values of k for the k-Nearest Neighbor classifier\n",
        "for k in kVals:\n",
        "    # Follow what we did in decision tree part\n",
        "    model = KNeighborsClassifier(n_neighbors=k)\n",
        "    model.fit(x_train, y_train.values.ravel())\n",
        "    \n",
        "    # Evaluate on Training set\n",
        "    train_pred2 =dt.predict(x_train) # One line of code\n",
        "    train_acc2 =accuracy_score(y_train.values.ravel(),train_pred) # One line of code\n",
        "    train_results2.append(train_acc)\n",
        "   \n",
        "  # Evaluate on Validation set\n",
        "    val_predknn = model.predict(x_val)# One line of code \n",
        "    val_accknn = accuracy_score(y_val.values.ravel(),val_predknn)# One line of code\n",
        "    val_results_Knn.append(val_accknn)\n",
        "    \n",
        "    score = model.score(x_val, y_val.values.ravel())\n",
        "    print(\"For k = %d, validation accuracy = %.5f%%\" % (k, score * 100))\n",
        "    accuracies.append(score)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(kVals, accuracies,'r')\n",
        "plt.plot(kVals, val_results_Knn,'b')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For k = 1, validation accuracy = 51.68067%\n",
            "For k = 3, validation accuracy = 53.78151%\n",
            "For k = 5, validation accuracy = 57.14286%\n",
            "For k = 7, validation accuracy = 60.92437%\n",
            "For k = 9, validation accuracy = 60.92437%\n",
            "For k = 11, validation accuracy = 64.70588%\n",
            "For k = 13, validation accuracy = 64.70588%\n",
            "For k = 15, validation accuracy = 63.44538%\n",
            "For k = 17, validation accuracy = 65.12605%\n",
            "For k = 19, validation accuracy = 66.80672%\n",
            "For k = 21, validation accuracy = 67.64706%\n",
            "For k = 23, validation accuracy = 68.48739%\n",
            "For k = 25, validation accuracy = 68.06723%\n",
            "For k = 27, validation accuracy = 67.64706%\n",
            "For k = 29, validation accuracy = 67.64706%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfdqDDjKFiDd",
        "colab_type": "code",
        "outputId": "cd6d412e-014f-4b08-b70a-ddee79b16a0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "# Train KNN using the full training data with the best K that you found\n",
        "i = np.argmax(accuracies)\n",
        "print(\"best k = %d with %.5f%% validation accuracy\" % (kVals[i], accuracies[i] * 100))\n",
        "model1 = KNeighborsClassifier(n_neighbors=kVals[i])\n",
        "model1.fit(train_data, train_label.values.ravel())\n",
        "predictions1 = model1.predict(test_data)\n",
        "\n",
        "# Testing\n",
        "from sklearn.metrics import accuracy_score\n",
        "TestAcc = accuracy_score(test_label.values.ravel(), predictions1)\n",
        "print(\"Testing Accuracy = %.5f%%\" % (TestAcc * 100))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best k = 23 with 68.48739% validation accuracy\n",
            "Testing Accuracy = 70.04831%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMEdOIlJQBin",
        "colab_type": "text"
      },
      "source": [
        "# Bonus\n",
        "\n",
        "# Apply gridsearch using decision tree on any hyperparameter(s) of your choice, you have to beat your previous obtained accuracies to get the bonus\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-9TxVbXQCw7",
        "colab_type": "code",
        "outputId": "81b66a25-5c42-4a5d-db24-698fe50c2fb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "# Write your code here\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "dt2=DecisionTreeClassifier()\n",
        "\n",
        "#Tuning hyperparameters \n",
        "parametersD3 = {\n",
        "              'criterion':['gini'],\n",
        "              'max_depth':list(range(1,15,2)),\n",
        "              'max_leaf_nodes':list(range(2,30)),\n",
        "             }\n",
        "acc_scorer = make_scorer(accuracy_score)\n",
        "\n",
        "\n",
        "# Running the grid search\n",
        "grid_obj = GridSearchCV(dt2, parametersD3, scoring=acc_scorer)\n",
        "grid_obj = grid_obj.fit(train_data, train_label)\n",
        "\n",
        "# Set the dt to the best combination of parameters\n",
        "dt2=DecisionTreeClassifier()\n",
        "dt2= grid_obj.best_estimator_\n",
        "print(dt2)\n",
        "# Fit the best algorithm to the data. \n",
        "dt2.fit(train_data,train_label)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=7, max_features=None, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=7, max_features=None, max_leaf_nodes=15,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxvWbhvdqVb9",
        "colab_type": "code",
        "outputId": "c0159034-806d-4e55-c20b-761d872386b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "#testing dt with best parameters\n",
        "predictions = dt2.predict(test_data)\n",
        "\n",
        "print(\"************************************\")\n",
        "print(\"Testing Accuracy of Previous Decision Tree = %.5f%%\" % (TestAccc * 100))\n",
        "\n",
        "print(\"************************************\")\n",
        "\n",
        "print(\"After Grid Search Testing Accuracy = %.5f%% \"%(accuracy_score(test_label, predictions)*100))\n",
        "print(\"************************************\")\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "************************************\n",
            "Testing Accuracy of Previous Decision Tree = 71.49758%\n",
            "************************************\n",
            "After Grid Search Testing Accuracy = 73.42995% \n",
            "************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VCH10cwnAU-",
        "colab_type": "text"
      },
      "source": [
        "# Report: Write a summary of your approach to this problem; this should be like an abstract of a paper or the executive summary (you aim for clarity and passing on information, not going to details about known facts such as what decision trees are, assuming they are known to people in your research area).\n",
        "\n",
        "Must include statements such as:\n",
        "\n",
        "\n",
        "*   Include the problem definition: 1-2 lines\n",
        "*   Talk about train/val/test sets, size and how split.\n",
        "*   State what your test results are with the chosen method, parameters: e.g. \"We have obtained the best results with the ….. classifier (parameters=....) , giving classification accuracy of …% on test data….\"\n",
        "*   Comment on the speed of the algorithms and anything else that you deem important/interesting (e.g. confusion matrix)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLTNonm8qUOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72KDasqHnt1T",
        "colab_type": "text"
      },
      "source": [
        "# Write your report in this cell\n",
        "\n",
        "REPORT\n",
        "--------------------\n",
        "**********************\n",
        "The dataset contains 1000 entries with 20 categorical attributes. Each\n",
        "entry represents a person who takes a credit by a bank. \n",
        "\n",
        "Task needed to be done is to classify a person as good or bad credit risks according to set of attributes.\n",
        "In our data, training and testing  data were already given seperatly. We divided this training data again 70% for training and 30% for validation.\n",
        "\n",
        "DECISION TREE CLASSIFIER \n",
        "**********\n",
        "First we classified with Decision Tree Classifier with default parameters.\n",
        "The result we obtain 67.63285% then we search for the Best Minimum Sample Split size\n",
        "among an array 2 to 100. Best result we obtained here with the validation set was  0.7226890756302521 with Minimum Sample Split size = 51.\n",
        "\n",
        "Then we trained our full training data Minimum Sample Split size = 51. We get the Testing Accuracy = 71.49758%. Which is an improvement after the result we obtained from default parametered Decision Tree.\n",
        "\n",
        "KNN\n",
        "**********\n",
        "In addition to the decision tree we used KNN classifier. What we get first with default parameters is Testing Accuracy = 67.63285%. We improved it by trying different k numbers between 1 and 30.(Only the odd numbers between). We obtained the best results on validation set when k = 23 with 68.48739% validation accuracy.\n",
        "\n",
        "Then we trained the whole training data with k=23 and we get the \n",
        "Testing Accuracy = 70.04831%\n",
        "\n",
        "COMPLEXITIES\n",
        "***********\n",
        "Assuming N is the number of rows in training data and F is the number of  features(columns) in data. D is the depth of the tree. Depends on how balanced it is we have complexity for the DT. \n",
        "\n",
        "      Between  O(NF log(D)) AND O((N^2)F) \n",
        "\n",
        "For KNN, its complexity depends on the data,if we take data points as N we will have complexity.\n",
        "      \n",
        "        O(N^2)\n",
        "In our case we have 1000 rows in total, approximately 800 rows our training data and 20 features and for DT, depth around 8.\n",
        "\n",
        "Since our data is not a large data to study on, we won't have big speed differences.\n",
        "\n",
        "For gridsearch we have tried 3 features on decision tree classifier. However we set criterion to Gini. We have O(N^2) complexity for grid search. \n",
        "\n",
        "BONUS PART\n",
        "**********\n",
        "For that part we need to get better results than the obtained before with different classifiers and parameters.\n",
        "What we got from DTC was Testing Accuracy = 71.49758%.\n",
        "\n",
        "What we got from KNN was Testing Accuracy = 70.04831%\n",
        "\n",
        "By applying grid search on DTC we have obtained Testing Accuracy = 73.42995% \n",
        "\n",
        "On this Grid search we have only tried these three parameters between given ranges.\n",
        "\n",
        "              'criterion':['gini'],\n",
        "              'max_depth':list(range(1,15,2)),\n",
        "              'max_leaf_nodes':list(range(2,30))\n",
        "\n",
        "             \n",
        "For information gain we tried Gini impurity instead of entropy and that resulted  in higher accuracy rate.\n",
        "Best parameters we have obtained for this result are :\n",
        "             \n",
        "              criterion='gini'\n",
        "              max_depth=7\n",
        "              max_leaf_nodes=15\n",
        "\n",
        "Hence we obtained a better result than the previous approaches with \n",
        "---------------------------------------------------------------------\n",
        "Testing Accuracy = 73.42995% \n",
        "---------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlDwn21lBD6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}